{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Usar matrix de interação"
      ],
      "metadata": {
        "id": "_Qa1i_l2IWC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd12h3caGwcP",
        "outputId": "610006e0-30bd-43e9-e1fb-64c76f5c0201"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Altair...\n",
            "Collecting git+git://github.com/altair-viz/altair.git\n",
            "  Cloning git://github.com/altair-viz/altair.git to /tmp/pip-req-build-_p9laoro\n",
            "  Running command git clone --filter=blob:none --quiet git://github.com/altair-viz/altair.git /tmp/pip-req-build-_p9laoro\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 73, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 491, in collect_root_requirements\n",
            "    req = self._make_requirement_from_install_req(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 453, in _make_requirement_from_install_req\n",
            "    cand = self._make_candidate_from_link(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 293, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 516, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 587, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 155, in unpack_url\n",
            "    unpack_vcs_link(link, location, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 78, in unpack_vcs_link\n",
            "    vcs_backend.unpack(location, url=hide_url(link.url), verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 608, in unpack\n",
            "    self.obtain(location, url=url, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 521, in obtain\n",
            "    self.fetch_new(dest, url, rev_options, verbosity=verbosity)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/git.py\", line 276, in fetch_new\n",
            "    self.run_command(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/vcs/versioncontrol.py\", line 650, in run_command\n",
            "    return call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 304, in line\n",
            "    if self.lineno is None:\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Done installing Altair.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.manifold\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# Add some convenience functions to Pandas DataFrame.\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "def mask(df, key, function):\n",
        "  \"\"\"Returns a filtered dataframe, by applying function to key\"\"\"\n",
        "  return df[function(df[key])]\n",
        "\n",
        "def flatten_cols(df):\n",
        "  df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
        "  return df\n",
        "\n",
        "pd.DataFrame.mask = mask\n",
        "pd.DataFrame.flatten_cols = flatten_cols\n",
        "\n",
        "# Install Altair and activate its colab renderer.\n",
        "print(\"Installing Altair...\")\n",
        "!pip install git+git://github.com/altair-viz/altair.git\n",
        "import altair as alt\n",
        "alt.data_transformers.enable('default', max_rows=None)\n",
        "alt.renderers.enable('colab')\n",
        "print(\"Done installing Altair.\")\n",
        "\n",
        "# Install spreadsheets and import authentication module.\n",
        "USER_RATINGS = False\n",
        "!pip install --upgrade -q gspread\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading movielens data...\")\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile\n",
        "\n",
        "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\", \"movielens.zip\")\n",
        "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "print(\"Done. Dataset contains:\")\n",
        "print(zip_ref.read('ml-100k/u.info'))\n",
        "\n",
        "# Load each data set (users, movies, and ratings).\n",
        "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
        "users = pd.read_csv(\n",
        "    'ml-100k/u.user', sep='|', names=users_cols, encoding='latin-1')\n",
        "\n",
        "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
        "ratings = pd.read_csv(\n",
        "    'ml-100k/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')\n",
        "\n",
        "# The movies file contains a binary feature for each genre.\n",
        "genre_cols = [\n",
        "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
        "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
        "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
        "]\n",
        "movies_cols = [\n",
        "    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
        "] + genre_cols\n",
        "movies = pd.read_csv(\n",
        "    'ml-100k/u.item', sep='|', names=movies_cols, encoding='latin-1')\n",
        "\n",
        "# Since the ids start at 1, we shift them to start at 0.\n",
        "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: str(x-1))\n",
        "movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: str(x-1))\n",
        "movies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\n",
        "ratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: str(x-1))\n",
        "ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: str(x-1))\n",
        "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))\n",
        "\n",
        "# Compute the number of movies to which a genre is assigned.\n",
        "genre_occurences = movies[genre_cols].sum().to_dict()\n",
        "\n",
        "# Since some movies can belong to more than one genre, we create different\n",
        "# 'genre' columns as follows:\n",
        "# - all_genres: all the active genres of the movie.\n",
        "# - genre: randomly sampled from the active genres.\n",
        "def mark_genres(movies, genres):\n",
        "  def get_random_genre(gs):\n",
        "    active = [genre for genre, g in zip(genres, gs) if g==1]\n",
        "    if len(active) == 0:\n",
        "      return 'Other'\n",
        "    return np.random.choice(active)\n",
        "  def get_all_genres(gs):\n",
        "    active = [genre for genre, g in zip(genres, gs) if g==1]\n",
        "    if len(active) == 0:\n",
        "      return 'Other'\n",
        "    return '-'.join(active)\n",
        "  movies['genre'] = [\n",
        "      get_random_genre(gs) for gs in zip(*[movies[genre] for genre in genres])]\n",
        "  movies['all_genres'] = [\n",
        "      get_all_genres(gs) for gs in zip(*[movies[genre] for genre in genres])]\n",
        "\n",
        "mark_genres(movies, genre_cols)\n",
        "\n",
        "# Create one merged DataFrame containing all the movielens data.\n",
        "movielens = ratings.merge(movies, on='movie_id').merge(users, on='user_id')\n",
        "\n",
        "# Utility to split the data into training and test sets.\n",
        "def split_dataframe(df, holdout_fraction=0.1):\n",
        "  \"\"\"Splits a DataFrame into training and test sets.\n",
        "  Args:\n",
        "    df: a dataframe.\n",
        "    holdout_fraction: fraction of dataframe rows to use in the test set.\n",
        "  Returns:\n",
        "    train: dataframe for training\n",
        "    test: dataframe for testing\n",
        "  \"\"\"\n",
        "  test = df.sample(frac=holdout_fraction, replace=False)\n",
        "  train = df[~df.index.isin(test.index)]\n",
        "  return train, test"
      ],
      "metadata": {
        "id": "H9DEnw30H6yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.describe()"
      ],
      "metadata": {
        "id": "QM31YKLgH-No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.describe(include=[np.object])"
      ],
      "metadata": {
        "id": "YHf1Mn7lIAVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "occupation_filter = alt.selection_multi(fields=[\"occupation\"])\n",
        "occupation_chart = alt.Chart().mark_bar().encode(\n",
        "    x=\"count()\",\n",
        "    y=alt.Y(\"occupation:N\"),\n",
        "    color=alt.condition(\n",
        "        occupation_filter,\n",
        "        alt.Color(\"occupation:N\", scale=alt.Scale(scheme='category20')),\n",
        "        alt.value(\"lightgray\")),\n",
        ").properties(width=300, height=300, selection=occupation_filter)\n",
        "\n",
        "# A function that generates a histogram of filtered data.\n",
        "def filtered_hist(field, label, filter):\n",
        "  \"\"\"Creates a layered chart of histograms.\n",
        "  The first layer (light gray) contains the histogram of the full data, and the\n",
        "  second contains the histogram of the filtered data.\n",
        "  Args:\n",
        "    field: the field for which to generate the histogram.\n",
        "    label: String label of the histogram.\n",
        "    filter: an alt.Selection object to be used to filter the data.\n",
        "  \"\"\"\n",
        "  base = alt.Chart().mark_bar().encode(\n",
        "      x=alt.X(field, bin=alt.Bin(maxbins=10), title=label),\n",
        "      y=\"count()\",\n",
        "  ).properties(\n",
        "      width=300,\n",
        "  )\n",
        "  return alt.layer(\n",
        "      base.transform_filter(filter),\n",
        "      base.encode(color=alt.value('lightgray'), opacity=alt.value(.7)),\n",
        "  ).resolve_scale(y='independent')"
      ],
      "metadata": {
        "id": "l9Z2TM66ICB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_ratings = (\n",
        "    ratings\n",
        "    .groupby('user_id', as_index=False)\n",
        "    .agg({'rating': ['count', 'mean']})\n",
        "    .flatten_cols()\n",
        "    .merge(users, on='user_id')\n",
        ")\n",
        "\n",
        "# Create a chart for the count, and one for the mean.\n",
        "alt.hconcat(\n",
        "    filtered_hist('rating count', '# ratings / user', occupation_filter),\n",
        "    filtered_hist('rating mean', 'mean user rating', occupation_filter),\n",
        "    occupation_chart,\n",
        "    data=users_ratings)"
      ],
      "metadata": {
        "id": "MxBYCNFBIETp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_ratings = movies.merge(\n",
        "    ratings\n",
        "    .groupby('movie_id', as_index=False)\n",
        "    .agg({'rating': ['count', 'mean']})\n",
        "    .flatten_cols(),\n",
        "    on='movie_id')\n",
        "\n",
        "genre_filter = alt.selection_multi(fields=['genre'])\n",
        "genre_chart = alt.Chart().mark_bar().encode(\n",
        "    x=\"count()\",\n",
        "    y=alt.Y('genre'),\n",
        "    color=alt.condition(\n",
        "        genre_filter,\n",
        "        alt.Color(\"genre:N\"),\n",
        "        alt.value('lightgray'))\n",
        ").properties(height=300, selection=genre_filter)"
      ],
      "metadata": {
        "id": "aP7dfYs_IGDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(movies_ratings[['title', 'rating count', 'rating mean']]\n",
        " .sort_values('rating count', ascending=False)\n",
        " .head(10))"
      ],
      "metadata": {
        "id": "TH9S4wnHII_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(movies_ratings[['title', 'rating count', 'rating mean']]\n",
        " .mask('rating count', lambda x: x > 20)\n",
        " .sort_values('rating mean', ascending=False)\n",
        " .head(10))"
      ],
      "metadata": {
        "id": "mPbmv_lrIKxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of ratings and average rating per movie.\n",
        "alt.hconcat(\n",
        "    filtered_hist('rating count', '# ratings / movie', genre_filter),\n",
        "    filtered_hist('rating mean', 'mean movie rating', genre_filter),\n",
        "    genre_chart,\n",
        "    data=movies_ratings)"
      ],
      "metadata": {
        "id": "zyD6Mu2jIMYE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}